{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c79a5c-3113-4789-a066-bb8e8b03a922",
   "metadata": {},
   "source": [
    "# Complete Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edc9206-d34e-48cc-aaea-6dffcd4c897d",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d3e17-23b1-43d9-8d35-b62513d3c301",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3d6d81-416f-4586-b196-8f7acd8683cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import ruptures as rpt\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor, OLSInfluence\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from scipy.stats import shapiro, kstest, jarque_bera\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e149b0-ac7f-4c6b-9965-7c6ac9387d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPA = False\n",
    "VISUALIZE_CPA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c209a",
   "metadata": {},
   "source": [
    "#### Raw data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d284b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_full = True\n",
    "if using_full:\n",
    "  orig_physio_dir = 'CASE_full/data/interpolated/physiological'\n",
    "  orig_annotations_dir = 'CASE_full/data/interpolated/annotations'\n",
    "  metadata_dir = 'CASE_full/metadata'\n",
    "  total_num_participants = 30\n",
    "else:\n",
    "# TODO: create another output base directory for snippet\n",
    "  orig_physio_dir = 'CASE_snippet/data/interpolated/physiological'\n",
    "  orig_annotations_dir = 'CASE_snippet/data/interpolated/annotations'\n",
    "  metadata_dir = 'CASE_snippet/metadata'\n",
    "  total_num_participants = 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8004f556-40ab-44bf-8536-2a7eb4525d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories for data saving\n",
    "preprocessed_data_dir = 'preprocessed_data'\n",
    "os.makedirs(preprocessed_data_dir, exist_ok=True)\n",
    "annotation_videos_dir = 'preprocessed_data/annotation_videos'\n",
    "physio_videos_dir = 'preprocessed_data/physio_videos'\n",
    "os.makedirs(annotation_videos_dir, exist_ok=True)\n",
    "os.makedirs(physio_videos_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec8b6c-63a9-4e78-8311-74d57544a867",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc986eb-ffd6-4568-bc81-d8a9d853b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads csv data\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "    \n",
    "    \n",
    "def find_data_folder(folder_path, start_path='/content/drive'):\n",
    "  '''\n",
    "    :file_path: The complete path of the folder that includes the files.\n",
    "    :start_path: The root folder on Drive from which we start the search\n",
    "  '''\n",
    "  #Search the root folder of the data and if found, continue searching the full path.\n",
    "  start_data_folder = folder_path.split('/')[0]\n",
    "  for root, dirs, files in os.walk(start_path):\n",
    "      if start_data_folder in dirs:\n",
    "          return os.path.join(root, folder_path)\n",
    "  raise Exception(f\"{start_data_folder} folder not found. Please check the directory structure.\")\n",
    "\n",
    "\n",
    "def plot_signal_segment(raw_signal, cleaned_signal, title, start_time, duration, sampling_rate=1000):\n",
    "    \"\"\" Utility. Makes two graphs of a raw and a cleaned signal for demonstration \"\"\"\n",
    "   \n",
    "    start_sample = int(start_time * sampling_rate)\n",
    "    end_sample = int((start_time + duration) * sampling_rate)\n",
    " \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    # Plot raw signal\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(raw_signal[start_sample:end_sample], label='Raw Signal')\n",
    "    plt.title(f'Raw {title} Segment ({start_time}-{start_time + duration} sec)')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot clean signal\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(cleaned_signal[start_sample:end_sample], label='Cleaned Signal')\n",
    "    plt.title(f'Cleaned {title} Segment ({start_time}-{start_time + duration} sec)')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def read_store_files(files_path, file_type='.csv'):\n",
    "  '''\n",
    "    :files_path: The complete Drive path that includes the files\n",
    "    :file_type: The type of file we are searching for\n",
    "  '''\n",
    "\n",
    "  data_list = []\n",
    "  files_names = []\n",
    "  for file in os.listdir(files_path):\n",
    "    if file.endswith(file_type):\n",
    "      file_path = os.path.join(files_path, file)\n",
    "      if file_type == '.csv':\n",
    "        data = pd.read_csv(file_path)\n",
    "      elif file_type == '.xlsx':\n",
    "        data = pd.read_excel(file_path)\n",
    "\n",
    "      data_list.append(data)\n",
    "      files_names.append(file)\n",
    "\n",
    "  return data_list, files_names\n",
    "\n",
    "\n",
    "def retrieve_metadata(metadata_dir):\n",
    "    # Retrieve metadata by reading the .xlsx files in the metadata_dir\n",
    "    metadata, metadata_names = read_store_files(metadata_dir,'.xlsx')\n",
    "    print(f'Metadata files: {metadata_names}')\n",
    "\n",
    "    # Strip column names from whitespace \n",
    "    for i in range(len(metadata)):\n",
    "        metadata[i].columns = metadata[i].columns.str.strip()\n",
    "\n",
    "    # Store each metadata file separately (based on name)\n",
    "    for i, file in enumerate(metadata_names):\n",
    "        if file == 'videos.xlsx':\n",
    "            videos_data = metadata[i].drop(metadata[i].columns[2:], axis=1).drop([0]).rename(columns={'Video-label': 'label', 'Video-ID': 'video_id'}).dropna()\n",
    "            videos_data['video_id'] = videos_data['video_id'].astype(int)\n",
    "        elif file == 'participants.xlsx':\n",
    "            participant_data = metadata[i].rename(columns={'Participant-ID': 'participant_id', 'Age-Group': 'age_group', 'Video Sequence Used': 'sequence'})\n",
    "        elif file == 'videos_duration_num.xlsx':\n",
    "            duration_data = metadata[i].rename(columns={'video-ID': 'video_id', 'video-duration (in ms)': 'duration'})\n",
    "        elif file == 'seqs_order_num.xlsx':\n",
    "            sequence_order_data = metadata[i]\n",
    "    \n",
    "    return videos_data, participant_data, duration_data, sequence_order_data\n",
    "# ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95792a-d9e6-4203-b132-443fcc5e332f",
   "metadata": {},
   "source": [
    "### Dependent Variables (Features Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a590c",
   "metadata": {},
   "source": [
    "#### Keep scary videos from annotation and physiological sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc5e7a2-ae9d-435a-8719-8c30e0964522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_scary_videos(num_participants, orig_data_dir, output_dir):\n",
    "        ''' \n",
    "        Keeps scary videos with a reset index\n",
    "        :num_participants: The number of participants\n",
    "        :current_dir: The directory that contains the annotation data from all the participants\n",
    "        '''\n",
    "        \n",
    "        print(f'Participant:', end=' ')\n",
    "        for participant in range(num_participants):\n",
    "            print(participant+1, end=', ')\n",
    "            # Read the participant's file\n",
    "            data = pd.read_csv(f'{orig_data_dir}/sub_{participant+1}.csv')\n",
    "\n",
    "            # Keep only the segments of scary-1 and scary-2\n",
    "            scary_1_segment = data[data['video'] == 7].reset_index(drop=True)\n",
    "            scary_2_segment = data[data['video'] == 8].reset_index(drop=True)\n",
    "            \n",
    "            if 'annotation' in orig_data_dir:\n",
    "                # Rename the index column to 'timepoint' and make it start from 0, increasing by 50\n",
    "                scary_1_segment.index = scary_1_segment.index * 50\n",
    "                scary_1_segment.index.name = 'timepoint'\n",
    "                \n",
    "                scary_2_segment.index = scary_2_segment.index * 50\n",
    "                scary_2_segment.index.name = 'timepoint'\n",
    "            else:\n",
    "                # Rename the index column to 'timepoint' \n",
    "                scary_1_segment.index.name = 'timepoint'\n",
    "                scary_2_segment.index.name = 'timepoint'\n",
    "            \n",
    "            # Save the extracted segments in CSV files\n",
    "            scary_1_segment.to_csv(f'{output_dir}/sub_{participant+1}_scary_1.csv')\n",
    "            scary_2_segment.to_csv(f'{output_dir}/sub_{participant+1}_scary_2.csv')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ef26d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed annotation files already exist.\n",
      "Skipping preprocessing...\n",
      "Preprocessed physiological files already exist.\n",
      "Skipping preprocessing...\n"
     ]
    }
   ],
   "source": [
    "annotation_files_list = os.listdir(annotation_videos_dir)\n",
    "physio_files_list = os.listdir(physio_videos_dir)\n",
    "\n",
    "if len(annotation_files_list) != total_num_participants * 2:\n",
    "    print('Keep the scary videos from the Annotation and Physiological sequences\\n')\n",
    "    print(f'- Annotation Sequences')\n",
    "    # Keep the two scary videos from each annotation sequence and store them in the \"annotation_videos_dir\"\n",
    "    keep_scary_videos(total_num_participants, orig_annotations_dir, annotation_videos_dir)\n",
    "else:\n",
    "    print(\"Preprocessed annotation files already exist.\\nSkipping preprocessing...\")\n",
    "\n",
    "if len(physio_files_list) != total_num_participants * 2:\n",
    "    print(f'- Physiological Sequences')\n",
    "    # Keep the two scary videos from each physiological sequence and store them in the \"physio_videos_dir\"\n",
    "    keep_scary_videos(total_num_participants, orig_physio_dir, physio_videos_dir)\n",
    "else:\n",
    "    print(\"Preprocessed physiological files already exist.\\nSkipping preprocessing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99681c07",
   "metadata": {},
   "source": [
    "#### Change Point Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7990473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cpa(num_participants, orig_annotations_dir, orig_physio_dir, annotation_videos_dir, \n",
    "              physio_videos_dir, annotations_after_cpa_dir, physio_after_cpa_dir):\n",
    "\n",
    "    def combine_valence_arousal(valence, arousal, neutral_value=5):\n",
    "        \"\"\" Adds the distance of valence and arousal from 5 (neutral_value) \"\"\"\n",
    "        combined_intensity = (valence - neutral_value).abs() + (arousal - neutral_value).abs()\n",
    "        return combined_intensity\n",
    "\n",
    "    def detect_change_points(df, model=\"rbf\", pen=20):\n",
    "        algo = rpt.Pelt(model=model).fit(df.values)\n",
    "        change_points = algo.predict(pen=pen)\n",
    "        return change_points\n",
    "\n",
    "    def get_segments_excluding_first_last(change_points, series_length):\n",
    "        \"\"\" Removes the first and last segment \"\"\"\n",
    "        if len(change_points) > 2:\n",
    "            return change_points[1], change_points[-2]\n",
    "        else:\n",
    "            return 0, series_length\n",
    "\n",
    "    print('1. Compute the average start and end change point (CP) for all annotation videos\\n')\n",
    "    # List of files in the annotation_videos and physio_videosdirectories\n",
    "    annotation_files = os.listdir(annotation_videos_dir)\n",
    "    physio_files = os.listdir(physio_videos_dir)\n",
    "\n",
    "    # Separate files for each video\n",
    "    files_scary_1 = [file for file in annotation_files if \"scary_1\" in file]\n",
    "    files_scary_2 = [file for file in annotation_files if \"scary_2\" in file]\n",
    "\n",
    "    def perform_cpa_on_annotations(files):\n",
    "        \"\"\" Processes files and get average start and end points for each scary video \"\"\"\n",
    "        all_start_points = []\n",
    "        all_end_points = []\n",
    "\n",
    "        print('File', end=': ')\n",
    "        for i, file in enumerate(files):\n",
    "            print(f\"{i+1}\", end=', ')\n",
    "            file_path = os.path.join(annotation_videos_dir, file)\n",
    "            data = load_csv_data(file_path)\n",
    "            \n",
    "            # Keep the valence column and the arousal column separately and call the function that combines their intensity\n",
    "            valence = data['valence']\n",
    "            arousal = data['arousal']\n",
    "\n",
    "            combined_intensity = combine_valence_arousal(valence, arousal)\n",
    "            \n",
    "            # Start with a standard pen value of 20\n",
    "            pen = 15\n",
    "            # Acceptable change points threshold\n",
    "            change_points_threshold = 8\n",
    "            \n",
    "            while True:\n",
    "                change_points = detect_change_points(combined_intensity.to_frame(), pen=pen)\n",
    "                # Increase the pen value (by 5) until the segments are <= change_points_threshold\n",
    "                if len(change_points) <= change_points_threshold:\n",
    "                    break\n",
    "                pen += 5\n",
    "            \n",
    "            # After the series is segmented using CPA, remove the first and the last segment\n",
    "            start, end = get_segments_excluding_first_last(change_points, len(combined_intensity))\n",
    "            \n",
    "            # Keep a list of all the start and end points so later the mean can be computed\n",
    "            all_start_points.append(start)\n",
    "            all_end_points.append(end)\n",
    "\n",
    "        # Keep the mean (average) of all start and end points as generar timestamps for our final segmentation\n",
    "        if all_start_points and all_end_points:\n",
    "            avg_start_point = int(np.mean(all_start_points))\n",
    "            avg_end_point = int(np.mean(all_end_points))\n",
    "        else:\n",
    "            avg_start_point, avg_end_point = 0, len(combined_intensity)  # Default to entire series if no points\n",
    "\n",
    "        return avg_start_point, avg_end_point\n",
    "\n",
    "\n",
    "    # Process files and get average start and end points for each video. One time for scary-1 and one time for scary-2\n",
    "    print(f'- CPA on Scary 1')\n",
    "    avg_start_scary_1, avg_end_scary_1 = perform_cpa_on_annotations(files_scary_1)\n",
    "    print(f'\\n- CPA on Scary 2')\n",
    "    avg_start_scary_2, avg_end_scary_2 = perform_cpa_on_annotations(files_scary_2)\n",
    "\n",
    "    print()\n",
    "    print(f\"\\nAverage start and end points for scary_1: {avg_start_scary_1}, {avg_end_scary_1}\")\n",
    "    print(f\"Average start and end points for scary_2: {avg_start_scary_2}, {avg_end_scary_2}\")\n",
    "    print('\\n','-'*50, '\\n')\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    print(\"2. Apply the average start and end points to each participant's Annotation and Physiological data\\n\")\n",
    "    \n",
    "    print('- Annotation data')\n",
    "    # Apply the average start and end points to each participant's data and save the new CSVs in the \"annotations_after_cpa_dir\"\n",
    "    print('File', end=': ')\n",
    "    for i, file in enumerate(annotation_files):\n",
    "        print(f\"{i+1}\", end=', ')\n",
    "        file_path = os.path.join(annotation_videos_dir, file)\n",
    "        data = load_csv_data(file_path)\n",
    "        \n",
    "        if \"scary_1\" in file:\n",
    "            start, end = avg_start_scary_1, avg_end_scary_1\n",
    "        else:\n",
    "            start, end = avg_start_scary_2, avg_end_scary_2\n",
    "        \n",
    "        most_significant_segment = data.iloc[start:end]\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_file_path = os.path.join(annotations_after_cpa_dir, f\"{os.path.splitext(file)[0]}_cpa.csv\")\n",
    "        most_significant_segment.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    print('\\n- Physiological data')\n",
    "    # Apply the average start and end points to each participant's data and save the new CSVs in the \"physio_after_cpa_dir\"\n",
    "    print('File', end=': ')\n",
    "    for i, file in enumerate(physio_files):\n",
    "        print(f\"{i+1}\", end=', ')\n",
    "        file_path = os.path.join(physio_videos_dir, file)\n",
    "        data = load_csv_data(file_path)\n",
    "        \n",
    "        if \"scary_1\" in file:\n",
    "            start, end = avg_start_scary_1*50, avg_end_scary_1*50\n",
    "        else:\n",
    "            start, end = avg_start_scary_2*50, avg_end_scary_2*50\n",
    "        \n",
    "        most_significant_segment = data.iloc[start:end]\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_file_path = os.path.join(physio_after_cpa_dir, f\"{os.path.splitext(file)[0]}_cpa.csv\")\n",
    "        most_significant_segment.to_csv(output_file_path, index=False)\n",
    "        \n",
    "\n",
    "    # Save average starting and ending times in a csv for later use\n",
    "    # These tme points are based on the segmented scary video and not the whole series\n",
    "    # For example if avg_start_scary_1 = 300, it means that the \"important\" part of the video data starts 300ms after the beginning of the video.\n",
    "    start_end_times = {\n",
    "        'Annotation Start scary_1': avg_start_scary_1, \n",
    "        'Annotation End scary_1': avg_end_scary_1, \n",
    "        'Annotation Start scary_2': avg_start_scary_2, \n",
    "        'Annotation End scary_2': avg_end_scary_2,\n",
    "        'Physio Start scary_1': avg_start_scary_1*50, \n",
    "        'Physio End scary_1': avg_end_scary_1*50, \n",
    "        'Physio Start scary_2': avg_start_scary_2*50, \n",
    "        'Physio End scary_2': avg_end_scary_2*50\n",
    "    }\n",
    "\n",
    "    # Save to CSV\n",
    "    pd.DataFrame([start_end_times]).to_csv('preprocessed_data/CPA_Start_End_times.csv', index=False)\n",
    "    print('\\n','-'*50, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85b3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cpa_results(annotation_videos_dir, physio_videos_dir):\n",
    "    print('5. Visualize the CPA segments\\n')\n",
    "    # NOTE: Change participant number to inpsect\n",
    "    participant_id = 2\n",
    "\n",
    "    # Example: Plot the annotation segments extracted from CPA\n",
    "    example_file_scary_1_annotation = pd.read_csv(f'{annotation_videos_dir}/sub_{participant_id}_scary_1.csv')\n",
    "    example_file_scary_2_annotation = pd.read_csv(f'{annotation_videos_dir}/sub_{participant_id}_scary_2.csv')\n",
    "\n",
    "    # Segments for video 1 and 2\n",
    "    segments = pd.read_csv('preprocessed_data/CPA_Start_End_times.csv')\n",
    "    segments_scary_1_annotation = [segments['Annotation Start scary_1'].values[0], segments['Annotation End scary_1'].values[0]]\n",
    "    segments_scary_2_annotation = [segments['Annotation Start scary_2'].values[0], segments['Annotation End scary_2'].values[0]]\n",
    "\n",
    "    print(\"1. Annotation Scary-1: Valence\")\n",
    "    print(\"2. Annotation Scary-1: Arousal\")\n",
    "    print(\"3. Annotation Scary-2: Valence\")\n",
    "    print(\"4. Annotation Scary-2: Arousal\")\n",
    "\n",
    "    rpt.display(example_file_scary_1_annotation['valence'], segments_scary_1_annotation)\n",
    "    rpt.display(example_file_scary_1_annotation['arousal'], segments_scary_1_annotation)\n",
    "    rpt.display(example_file_scary_2_annotation['valence'], segments_scary_2_annotation)\n",
    "    rpt.display(example_file_scary_2_annotation['arousal'], segments_scary_2_annotation)\n",
    "\n",
    "\n",
    "    # Example: Plot the physio segments extracted from CPA\n",
    "    example_file_scary_1_physio = pd.read_csv(f'{physio_videos_dir}/sub_{participant_id}_scary_1.csv')\n",
    "    example_file_scary_2_physio = pd.read_csv(f'{physio_videos_dir}/sub_{participant_id}_scary_2.csv')\n",
    "\n",
    "    # Segpents for video 1 and 2\n",
    "    segments = pd.read_csv('preprocessed_data/CPA_Start_End_times.csv')\n",
    "    segments_scary_1_physio = [segments['Physio Start scary_1'].values[0], segments['Physio End scary_1'].values[0]]\n",
    "    segments_scary_2_physio = [segments['Physio Start scary_2'].values[0], segments['Physio End scary_2'].values[0]]\n",
    "\n",
    "    print(\"\\n5. Physio Scary-1: ECG\")\n",
    "    print(\"6. Physio Scary-1: GSR\")\n",
    "    print(\"7. Physio Scary-2: ECG\")\n",
    "    print(\"8. Physio Scary-2: GSR\")\n",
    "\n",
    "    rpt.display(example_file_scary_1_physio['ecg'], segments_scary_1_physio)\n",
    "    rpt.display(example_file_scary_1_physio['gsr'], segments_scary_1_physio)\n",
    "    rpt.display(example_file_scary_2_physio['ecg'], segments_scary_2_physio)\n",
    "    rpt.display(example_file_scary_2_physio['gsr'], segments_scary_2_physio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed2aa35c-4529-4f83-a22e-54fd3d009160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CPA (Note: this can take up to 30+ minutes)\n",
    "if CPA:\n",
    "    # Define Directory paths\n",
    "    annotations_after_cpa_dir = 'preprocessed_data/annotations_after_cpa'\n",
    "    physio_after_cpa_dir = 'preprocessed_data/physio_after_cpa'\n",
    "\n",
    "    # Make sure that the directories exist\n",
    "    os.makedirs(annotations_after_cpa_dir, exist_ok=True)\n",
    "    os.makedirs(physio_after_cpa_dir, exist_ok=True)\n",
    "    \n",
    "    annotation_files_after_cpa_list = os.listdir(annotations_after_cpa_dir)\n",
    "    physio_files_after_cpa_list = os.listdir(physio_after_cpa_dir)\n",
    "    \n",
    "    if len(annotation_files_after_cpa_list) != total_num_participants*2 or len(physio_files_after_cpa_list) != total_num_participants*2:\n",
    "        apply_cpa(total_num_participants, orig_annotations_dir, orig_physio_dir, annotation_videos_dir, \n",
    "                physio_videos_dir, annotations_after_cpa_dir, physio_after_cpa_dir)\n",
    "    else:\n",
    "        print('CPA has already been applied!')\n",
    "    \n",
    "\n",
    "    if VISUALIZE_CPA:\n",
    "        visualize_cpa_results(annotation_videos_dir, physio_videos_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d13170d-60e5-4937-aef8-f340e478d627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41ccf1d2-3874-4e73-8b01-26bfffef5a51",
   "metadata": {},
   "source": [
    "##### Clean Signal and Extract Features from ECG and GSR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6afa7dc-03c6-48d5-8231-b3931d9ed7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_scary_videos(df1, df2):\n",
    "    \"\"\" Swaps df scary videos order dependent on their original timestamp \"\"\"\n",
    "    if df1['daqtime'].iloc[0] > df2['daqtime'].iloc[0]:\n",
    "        return True, df2, df1\n",
    "    return False, df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ef787f-0e80-419c-a198-b09eca67b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_signal(signal, data_type, visualization=False):\n",
    "    \"\"\" Just cleans the signal (NOTE: ok for now).\n",
    "    Set visualization to True to see a before-after example\n",
    "    \"\"\"\n",
    "    if data_type == \"ecg\":\n",
    "        cleaned_signal = nk.ecg_clean(signal, sampling_rate=1000)\n",
    "    elif data_type == \"gsr\":\n",
    "        cleaned_signal = nk.eda_clean(signal, sampling_rate=1000)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type\")\n",
    "\n",
    "    if visualization:\n",
    "        # Plot a 5-second segment for demonstration\n",
    "        plot_signal_segment(signal, cleaned_signal, 'Signal', start_time=20, duration=5 if data_type=='ecg' else 200)\n",
    "    return cleaned_signal\n",
    "\n",
    "def extract_segments(cleaned_signal, start_time, end_time, original_timestamps):\n",
    "    \"\"\" Utility. Extracts the signal segment given timestamps \"\"\"\n",
    "    start_index = original_timestamps[original_timestamps >= start_time].index[0]\n",
    "    end_index = original_timestamps[original_timestamps <= end_time].index[-1]\n",
    "\n",
    "    segment = cleaned_signal[start_index:end_index+1]\n",
    "    return segment\n",
    "\n",
    "\n",
    "def extract_features(segment, data_type, sampling_rate=1000):\n",
    "    \"\"\" Extracts ECG and GSR features.\n",
    "\n",
    "    ECG:\n",
    "    - Heart Rate: Mean heart rate over the segment.\n",
    "    - HRV SDNN: Standard deviation of NN intervals (HRV time-domain).\n",
    "    - Mean RR Interval: Mean of RR intervals.\n",
    "    GSR:\n",
    "    - SCL: Skin conductance level (mean tonic level).\n",
    "    - SCR: Skin conductance response (mean phasic level).\n",
    "    - Peak Amplitude: Maximum amplitude of the SCR peaks.\n",
    "\n",
    "    Parameters:\n",
    "    - segment: Array-like, the segment of the signal to analyze.\n",
    "    - data_type: str, type of the signal (\"ecg\" or \"gsr\").\n",
    "    - sampling_rate: int, sampling rate of the signal in Hz.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the extracted features.\n",
    "    \"\"\"\n",
    "    if data_type == \"ecg\":\n",
    "        signals, info = nk.ecg_process(segment, sampling_rate=sampling_rate)\n",
    "        heart_rate = signals['ECG_Rate']\n",
    "\n",
    "        peaks, info = nk.ecg_peaks(segment, sampling_rate=sampling_rate)\n",
    "        hrv_time = nk.hrv_time(peaks, sampling_rate=sampling_rate).iloc[0].to_dict()\n",
    "\n",
    "        features = {\n",
    "            \"Heart Rate\": heart_rate.mean(),\n",
    "            \"HRV SDNN\": hrv_time['HRV_SDNN'],\n",
    "            \"Mean RR Interval\": hrv_time['HRV_MeanNN']\n",
    "        }\n",
    "    elif data_type == \"gsr\":\n",
    "        signals, info = nk.eda_process(segment, sampling_rate=sampling_rate)\n",
    "        scl = signals['EDA_Tonic'].mean()\n",
    "        scr = signals['EDA_Phasic'].mean()\n",
    "\n",
    "        # peaks, info = nk.eda_peaks(segment, sampling_rate=sampling_rate)\n",
    "        peak_amplitude = signals['EDA_Phasic'].max()\n",
    "\n",
    "        features = {\n",
    "            \"SCL\": scl,\n",
    "            \"SCR\": scr,\n",
    "            \"Peak Amplitude\": peak_amplitude\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a0e16a-cda2-48fa-b57a-9178ebc928dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7984fcfd-8494-4925-b4b6-16de7f37b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on Physio data directory based on whether CPA was applied\n",
    "scary_physio_dir = physio_after_cpa_dir if CPA else physio_videos_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e0a789-59c2-47ae-a781-58d19a2daf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target file already exist. Features already exctracted.\n",
      "Skipping processing...\n"
     ]
    }
   ],
   "source": [
    "if CPA:\n",
    "    dv_features_output_filepath = 'preprocessed_data/dv_data_cpa.csv'\n",
    "else:\n",
    "    dv_features_output_filepath = 'preprocessed_data/dv_data.csv'\n",
    "\n",
    "# Check if the target file exists\n",
    "if not os.path.exists(dv_features_output_filepath):\n",
    "        \n",
    "    # Initialize list (NOTE: we will convert to dataframe later)\n",
    "    results = []\n",
    "    \n",
    "    # Features extraction loops\n",
    "    for sub_num in range(1, total_num_participants+1):\n",
    "        print(f\"\\n- Participant {sub_num}\")\n",
    "    \n",
    "        # Define file names   \n",
    "        if CPA:     \n",
    "            scary_1_filename = f'sub_{sub_num}_scary_1_cpa.csv'\n",
    "            scary_2_filename = f'sub_{sub_num}_scary_2_cpa.csv'\n",
    "        else:\n",
    "            scary_1_filename = f'sub_{sub_num}_scary_1.csv'\n",
    "            scary_2_filename = f'sub_{sub_num}_scary_2.csv'\n",
    "\n",
    "        scary_1 = load_csv_data(os.path.join(scary_physio_dir, scary_1_filename))\n",
    "        scary_2 = load_csv_data(os.path.join(scary_physio_dir, scary_2_filename))\n",
    "    \n",
    "        # Swap with \n",
    "        swapped, scary_1st, scary_2nd = swap_scary_videos(scary_1, scary_2)\n",
    "    \n",
    "        # Get the start and end timestamps\n",
    "        scary_1st_start, scary_1st_end = scary_1st['daqtime'].iloc[0], scary_1st['daqtime'].iloc[-1]\n",
    "        scary_2nd_start, scary_2nd_end = scary_2nd['daqtime'].iloc[0], scary_2nd['daqtime'].iloc[-1]\n",
    "        \n",
    "        print(f\"scary_1st_start: {scary_1st_start}, scary_1st_end: {scary_1st_end}, scary_2nd_start: {scary_2nd_start}, scary_2nd_end: {scary_2nd_end}\")\n",
    "    \n",
    "        if swapped: print(\"Scary videos sequence swapped for chronological order\")\n",
    "    \n",
    "        # Clean each segment separately\n",
    "        ecg_cleaned_scary_1st = pd.Series(preprocess_signal(scary_1st['ecg'], data_type=\"ecg\", visualization=False))\n",
    "        ecg_cleaned_scary_2nd = pd.Series(preprocess_signal(scary_2nd['ecg'], data_type=\"ecg\", visualization=False))\n",
    "        gsr_cleaned_scary_1st = pd.Series(preprocess_signal(scary_1st['gsr'], data_type=\"gsr\", visualization=False))\n",
    "        gsr_cleaned_scary_2nd = pd.Series(preprocess_signal(scary_2nd['gsr'], data_type=\"gsr\", visualization=False))\n",
    "    \n",
    "        # Concatenate the cleaned segments\n",
    "        ecg_cleaned = pd.concat([ecg_cleaned_scary_1st, ecg_cleaned_scary_2nd], ignore_index=True)\n",
    "        gsr_cleaned = pd.concat([gsr_cleaned_scary_1st, gsr_cleaned_scary_2nd], ignore_index=True)\n",
    "    \n",
    "        original_timestamps = pd.concat([scary_1st['daqtime'], scary_2nd['daqtime']], ignore_index=True)\n",
    "    \n",
    "        # Extract segment data (NOTE: something like this could be used later even if we segment the videos further)\n",
    "        ecg_scary_1st_segment = extract_segments(ecg_cleaned, scary_1st_start, scary_1st_end, original_timestamps)\n",
    "        ecg_scary_2nd_segment = extract_segments(ecg_cleaned, scary_2nd_start, scary_2nd_end, original_timestamps)\n",
    "    \n",
    "        gsr_scary_1st_segment = extract_segments(gsr_cleaned, scary_1st_start, scary_1st_end, original_timestamps)\n",
    "        gsr_scary_2nd_segment = extract_segments(gsr_cleaned, scary_2nd_start, scary_2nd_end, original_timestamps)\n",
    "    \n",
    "        # Calculate ECG and GSR features for both videos\n",
    "        ecg_features_scary_1st = extract_features(ecg_scary_1st_segment, data_type=\"ecg\")\n",
    "        ecg_features_scary_2nd = extract_features(ecg_scary_2nd_segment, data_type=\"ecg\")\n",
    "    \n",
    "        gsr_features_scary_1st = extract_features(gsr_scary_1st_segment, data_type=\"gsr\")\n",
    "        gsr_features_scary_2nd = extract_features(gsr_scary_2nd_segment, data_type=\"gsr\")\n",
    "    \n",
    "        # Calculate differences for all features (to use in statistical analysis)\n",
    "        ecg_features_diff = {f'diff_ecg_{key}': ecg_features_scary_2nd[key] - ecg_features_scary_1st[key] for key in ecg_features_scary_1st.keys()}\n",
    "        gsr_features_diff = {f'diff_gsr_{key}': gsr_features_scary_2nd[key] - gsr_features_scary_1st[key] for key in gsr_features_scary_1st.keys()}\n",
    "    \n",
    "        # Compile all features into a single dictionary\n",
    "        participant_features = {'participant': sub_num}\n",
    "        participant_features.update({f'scary_1st_ecg_{key}': value for key, value in ecg_features_scary_1st.items()})\n",
    "        participant_features.update({f'scary_2nd_ecg_{key}': value for key, value in ecg_features_scary_2nd.items()})\n",
    "        participant_features.update(ecg_features_diff)\n",
    "        participant_features.update({f'scary_1st_gsr_{key}': value for key, value in gsr_features_scary_1st.items()})\n",
    "        participant_features.update({f'scary_2nd_gsr_{key}': value for key, value in gsr_features_scary_2nd.items()})\n",
    "        participant_features.update(gsr_features_diff)\n",
    "    \n",
    "        # Add to results\n",
    "        results.append(participant_features)\n",
    "        print(\"ECG and GSR features successfully extracted.\\n\")\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save\n",
    "    results_df.to_csv(dv_features_output_filepath, index=False)\n",
    "    \n",
    "    print(f\"\\n\\nResults saved to {dv_features_output_filepath}.\")\n",
    "else:\n",
    "    print(\"Target file already exist. Features already exctracted.\\nSkipping processing...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28932253-dacb-4d5b-88e4-959a28be9b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a11622a",
   "metadata": {},
   "source": [
    "### Independent Variables (Predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79abc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_independent_variables(sequence_order_data, participant_data, \n",
    "                                    videos_data, num_participants, results_name='preprocessed_data/iv_data.csv'):\n",
    "    \n",
    "    '''\n",
    "    :sequence_order_data: Dataframe where each column is a participant and the rows are the sequence of videos whatched\n",
    "    :participant_data: Dataframe that includes information about each participant. We use it to extract the sequence ID\n",
    "    :videos_data: Includes the label, ID and duration of each video\n",
    "    :num_participants: The number of participants\n",
    "    :results_name: Name of the result CSV file that will contain the Independent Variables for each participant.\n",
    "    '''\n",
    "\n",
    "    # Extract video IDs based on labels\n",
    "    def extract_video_ids(label_list, videos_data):\n",
    "        return videos_data[videos_data['label'].isin(label_list)].drop(columns=('label'))['video_id'].tolist()\n",
    "    \n",
    "    def compute_start_end_points(num_participants):        \n",
    "        # Initialize start end points dict\n",
    "        start_end_points = {'scary_1st_start': [], 'scary_1st_end': [], 'scary_2nd_start': [], 'scary_2nd_end': []}\n",
    "        \n",
    "        for sub_num in range(1, num_participants+1):\n",
    "\n",
    "            scary_1_filename = f'sub_{sub_num}_scary_1.csv'\n",
    "            scary_2_filename = f'sub_{sub_num}_scary_2.csv'\n",
    "            # # Define file names   \n",
    "            # if CPA:     \n",
    "            #     scary_1_filename = f'sub_{sub_num}_scary_1_cpa.csv'\n",
    "            #     scary_2_filename = f'sub_{sub_num}_scary_2_cpa.csv'\n",
    "            # else:\n",
    "            #     scary_1_filename = f'sub_{sub_num}_scary_1.csv'\n",
    "            #     scary_2_filename = f'sub_{sub_num}_scary_2.csv'\n",
    "            \n",
    "            # Retrieve data\n",
    "            scary_1 = load_csv_data(os.path.join(physio_videos_dir, scary_1_filename))\n",
    "            scary_2 = load_csv_data(os.path.join(physio_videos_dir, scary_2_filename))\n",
    "            \n",
    "            # Swap if needed \n",
    "            _, scary_1st, scary_2nd = swap_scary_videos(scary_1, scary_2)\n",
    "\n",
    "            # Get the start and end timestamps\n",
    "            scary_1st_start, scary_1st_end = scary_1st['daqtime'].iloc[0], scary_1st['daqtime'].iloc[-1]\n",
    "            scary_2nd_start, scary_2nd_end = scary_2nd['daqtime'].iloc[0], scary_2nd['daqtime'].iloc[-1]\n",
    "                        \n",
    "            start_end_points['scary_1st_start'].append(scary_1st_start)\n",
    "            start_end_points['scary_1st_end'].append(scary_1st_end)\n",
    "            start_end_points['scary_2nd_start'].append(scary_2nd_start)\n",
    "            start_end_points['scary_2nd_end'].append(scary_2nd_end)\n",
    "\n",
    "\n",
    "        pd.DataFrame(start_end_points).to_csv('preprocessed_data/start_end_points.csv', index=False)\n",
    "\n",
    "    \n",
    "    SCARY_LABELS=['scary-1', 'scary-2']\n",
    "    LOW_AROUSAL_LABELS=['relaxed-1', 'relaxed-2', 'boring-1', 'boring-2']\n",
    "\n",
    "    scary_videos_ids = extract_video_ids(SCARY_LABELS, videos_data) # IDs of the scary videos\n",
    "    low_arousal_videos_ids = extract_video_ids(LOW_AROUSAL_LABELS, videos_data) # IDs of the low arousal videos\n",
    "    print(f'Scary videos IDs: {scary_videos_ids}\\nLow Arousal videos IDs: {low_arousal_videos_ids}')\n",
    "    \n",
    "    # Create and read the scary videos starting and ending points from the csv file\n",
    "    compute_start_end_points(num_participants)\n",
    "    start_end_points_df = pd.read_csv('preprocessed_data/start_end_points.csv')\n",
    "    \n",
    "    # Initialize data arrays\n",
    "    def initialize_arrays(shape, fill_value=0):\n",
    "        return np.zeros(shape) + fill_value\n",
    "    \n",
    "    interlude_durations = initialize_arrays(num_participants) # Interlude time between scary videos for each participant\n",
    "    count_interlude_videos_total = initialize_arrays(num_participants)  # Initialize count of interlude videos total\n",
    "    count_interlude_low_arousal = initialize_arrays(num_participants) # Initialize count of interlude low arousal\n",
    "    logratio_low_div_total = initialize_arrays(num_participants)  # Initialize log ratio (low arousal / total interlude)\n",
    "    \n",
    "    # Extract the sequence ID of each participant. It is the same as the participant number but we extract it this way in case the .xlsx change.\n",
    "    sequence_id_of_participants = np.array([participant_data.iloc[participant]['sequence'] for participant in range(num_participants)])\n",
    "\n",
    "    # Helper function to compute log ratio\n",
    "    def compute_log_ratio(count_low, count_total):\n",
    "        return np.around(np.log((count_low + 1) / (count_total + 1)), decimals=4)\n",
    "    \n",
    "    # Process each participant\n",
    "    for participant in range(num_participants):\n",
    "        print(f'Participant {participant + 1}')\n",
    "        \n",
    "        # Using the sequence id, get the video sequence of the specific participant \n",
    "        participant_sequence = pd.DataFrame(sequence_order_data[f'sub_{sequence_id_of_participants[participant]}']).rename(columns={f'sub_{participant+1}': 'sequence'})\n",
    "        print(f'- Sequence ID: {sequence_id_of_participants[participant]}')\n",
    "        print(f'- Sequence: {participant_sequence[\"sequence\"].tolist()}')\n",
    "        \n",
    "        # Retrieve scary video start and end \n",
    "        scary_1st_start, scary_1st_end, scary_2nd_start, scary_2nd_end = \\\n",
    "        start_end_points_df['scary_1st_start'].iloc[participant], start_end_points_df['scary_1st_end'].iloc[participant], \\\n",
    "        start_end_points_df['scary_2nd_start'].iloc[participant], start_end_points_df['scary_2nd_end'].iloc[participant]\n",
    "        print(f'- Timepoints: Scary 1st start: {scary_1st_start} || Scary 1st end: {scary_1st_end} || Scary 2nd start: {scary_2nd_start} || Scary 2nd end: {scary_2nd_end}')\n",
    "\n",
    "        # Find locations of the two scary videos in the sequence\n",
    "        scary_indices = participant_sequence[participant_sequence['sequence'].isin(scary_videos_ids)].index.values.tolist()\n",
    "        first_scary_loc, second_scary_loc = scary_indices[0], scary_indices[1]\n",
    "        print(f'- Locs in sequence: Scary 1st: {first_scary_loc} || Scary 2nd: {second_scary_loc}')\n",
    "        \n",
    "        # Retrieve all the Interlude videos based on the sequence and the 1st & 2nd scary locations. (if any)\n",
    "        interlude_videos = participant_sequence.iloc[first_scary_loc + 1 : second_scary_loc][f'sequence'].values.tolist() if second_scary_loc > first_scary_loc + 1 else []\n",
    "        count_interlude_videos_total[participant] = np.floor(len(interlude_videos) / 2) # Divide by 2 so we don't count the bluVid between each video\n",
    "        print(f'- Number of interlude videos (no bluVid): {int(count_interlude_videos_total[participant])}')\n",
    "        \n",
    "        # Compute Low Arousal Interlude videos\n",
    "        count_interlude_low_arousal[participant] = len([vid for vid in interlude_videos if vid in low_arousal_videos_ids])\n",
    "        print(f'- Low Arousal Interlude videos: {int(count_interlude_low_arousal[participant])}')\n",
    "        \n",
    "        # Compute the Log Ratio between the total Interlude videos and the Low Arousal Interlude videos  \n",
    "        logratio_low_div_total[participant] = compute_log_ratio(count_interlude_low_arousal[participant], count_interlude_videos_total[participant])\n",
    "        print(f'- Log Ratio: {logratio_low_div_total[participant]}')\n",
    "        \n",
    "        # Compute Interlude Durations\n",
    "        interlude_durations[participant] = scary_2nd_start - scary_1st_end\n",
    "        print(f'- Interlude duration (with bluVid): {interlude_durations[participant]}')\n",
    "        \n",
    "    # Save the extracted features in dictionary and save it as dataframe CSV\n",
    "    data = {\n",
    "        'Participant': range(1, num_participants + 1),\n",
    "        'InterludeDuration': interlude_durations[:],\n",
    "        'Interlude Video Count': count_interlude_videos_total[:],\n",
    "        'Interlude Low Arousal': count_interlude_low_arousal[:],\n",
    "        'LowArousalRatioLog': logratio_low_div_total[:],\n",
    "    }\n",
    "    results_df = pd.DataFrame(data)\n",
    "\n",
    "    results_df.to_csv(results_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8752cc6e-7183-44c5-a7c2-c0d2b5591757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata files: ['videos.xlsx', 'participants.xlsx', 'seqs_order_num.xlsx', 'videos_duration_num.xlsx']\n",
      "Scary videos IDs: [7, 8]\n",
      "Low Arousal videos IDs: [3, 4, 5, 6]\n",
      "Participant 1\n",
      "- Sequence ID: 1\n",
      "- Sequence: [10, 11, 3, 11, 1, 11, 5, 11, 7, 11, 4, 11, 2, 11, 6, 11, 8, 12]\n",
      "- Timepoints: Scary 1st start: 1030876 || Scary 1st end: 1227875 || Scary 2nd start: 2187834 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 8 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: -0.2877\n",
      "- Interlude duration (with bluVid): 959959.0\n",
      "Participant 2\n",
      "- Sequence ID: 2\n",
      "- Sequence: [10, 11, 2, 11, 6, 11, 4, 11, 8, 11, 1, 11, 3, 11, 5, 11, 7, 12]\n",
      "- Timepoints: Scary 1st start: 1061459 || Scary 1st end: 1205208 || Scary 2nd start: 2134584 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 8 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: -0.2877\n",
      "- Interlude duration (with bluVid): 929376.0\n",
      "Participant 3\n",
      "- Sequence ID: 3\n",
      "- Sequence: [10, 11, 5, 11, 7, 11, 1, 11, 3, 11, 2, 11, 4, 11, 8, 11, 6, 12]\n",
      "- Timepoints: Scary 1st start: 486626 || Scary 1st end: 683625 || Scary 2nd start: 1921084 || Scary 2nd end: 2064833\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 4\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: -0.5108\n",
      "- Interlude duration (with bluVid): 1237459.0\n",
      "Participant 4\n",
      "- Sequence ID: 4\n",
      "- Sequence: [10, 11, 4, 11, 2, 11, 8, 11, 6, 11, 3, 11, 5, 11, 7, 11, 1, 12]\n",
      "- Timepoints: Scary 1st start: 794709 || Scary 1st end: 938458 || Scary 2nd start: 1829001 || Scary 2nd end: 2026000\n",
      "- Locs in sequence: Scary 1st: 6 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 3\n",
      "- Log Ratio: 0.0\n",
      "- Interlude duration (with bluVid): 890543.0\n",
      "Participant 5\n",
      "- Sequence ID: 5\n",
      "- Sequence: [10, 11, 1, 11, 7, 11, 5, 11, 3, 11, 8, 11, 2, 11, 4, 11, 6, 12]\n",
      "- Timepoints: Scary 1st start: 527084 || Scary 1st end: 724083 || Scary 2nd start: 1347876 || Scary 2nd end: 1491625\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 10\n",
      "- Number of interlude videos (no bluVid): 2\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: 0.0\n",
      "- Interlude duration (with bluVid): 623793.0\n",
      "Participant 6\n",
      "- Sequence ID: 6\n",
      "- Sequence: [10, 11, 6, 11, 8, 11, 4, 11, 2, 11, 7, 11, 3, 11, 5, 11, 1, 12]\n",
      "- Timepoints: Scary 1st start: 488251 || Scary 1st end: 632000 || Scary 2nd start: 1325209 || Scary 2nd end: 1522208\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 10\n",
      "- Number of interlude videos (no bluVid): 2\n",
      "- Low Arousal Interlude videos: 1\n",
      "- Log Ratio: -0.4055\n",
      "- Interlude duration (with bluVid): 693209.0\n",
      "Participant 7\n",
      "- Sequence ID: 7\n",
      "- Sequence: [10, 11, 5, 11, 3, 11, 7, 11, 1, 11, 4, 11, 2, 11, 8, 11, 6, 12]\n",
      "- Timepoints: Scary 1st start: 725293 || Scary 1st end: 922292 || Scary 2nd start: 1921084 || Scary 2nd end: 2064833\n",
      "- Locs in sequence: Scary 1st: 6 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 1\n",
      "- Log Ratio: -0.6931\n",
      "- Interlude duration (with bluVid): 998792.0\n",
      "Participant 8\n",
      "- Sequence ID: 8\n",
      "- Sequence: [10, 11, 3, 11, 5, 11, 1, 11, 7, 11, 4, 11, 2, 11, 6, 11, 8, 12]\n",
      "- Timepoints: Scary 1st start: 1030876 || Scary 1st end: 1227875 || Scary 2nd start: 2187834 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 8 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: -0.2877\n",
      "- Interlude duration (with bluVid): 959959.0\n",
      "Participant 9\n",
      "- Sequence ID: 9\n",
      "- Sequence: [10, 11, 2, 11, 4, 11, 6, 11, 8, 11, 3, 11, 5, 11, 1, 11, 7, 12]\n",
      "- Timepoints: Scary 1st start: 1061459 || Scary 1st end: 1205208 || Scary 2nd start: 2134584 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 8 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: -0.2877\n",
      "- Interlude duration (with bluVid): 929376.0\n",
      "Participant 10\n",
      "- Sequence ID: 10\n",
      "- Sequence: [10, 11, 8, 11, 6, 11, 4, 11, 2, 11, 3, 11, 1, 11, 5, 11, 7, 12]\n",
      "- Timepoints: Scary 1st start: 221501 || Scary 1st end: 365250 || Scary 2nd start: 2134584 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 2 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 6\n",
      "- Low Arousal Interlude videos: 4\n",
      "- Log Ratio: -0.3365\n",
      "- Interlude duration (with bluVid): 1769334.0\n",
      "Participant 11\n",
      "- Sequence ID: 11\n",
      "- Sequence: [10, 11, 3, 11, 7, 11, 1, 11, 5, 11, 8, 11, 4, 11, 2, 11, 6, 12]\n",
      "- Timepoints: Scary 1st start: 460168 || Scary 1st end: 657167 || Scary 2nd start: 1347876 || Scary 2nd end: 1491625\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 10\n",
      "- Number of interlude videos (no bluVid): 2\n",
      "- Low Arousal Interlude videos: 1\n",
      "- Log Ratio: -0.4055\n",
      "- Interlude duration (with bluVid): 690709.0\n",
      "Participant 12\n",
      "- Sequence ID: 12\n",
      "- Sequence: [10, 11, 4, 11, 2, 11, 6, 11, 8, 11, 5, 11, 3, 11, 7, 11, 1, 12]\n",
      "- Timepoints: Scary 1st start: 1061459 || Scary 1st end: 1205208 || Scary 2nd start: 1829001 || Scary 2nd end: 2026000\n",
      "- Locs in sequence: Scary 1st: 8 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 2\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: 0.0\n",
      "- Interlude duration (with bluVid): 623793.0\n",
      "Participant 13\n",
      "- Sequence ID: 13\n",
      "- Sequence: [10, 11, 5, 11, 3, 11, 7, 11, 1, 11, 6, 11, 2, 11, 4, 11, 8, 12]\n",
      "- Timepoints: Scary 1st start: 725293 || Scary 1st end: 922292 || Scary 2nd start: 2187834 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 6 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 4\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: -0.5108\n",
      "- Interlude duration (with bluVid): 1265542.0\n",
      "Participant 14\n",
      "- Sequence ID: 14\n",
      "- Sequence: [10, 11, 2, 11, 4, 11, 8, 11, 6, 11, 7, 11, 1, 11, 3, 11, 5, 12]\n",
      "- Timepoints: Scary 1st start: 794709 || Scary 1st end: 938458 || Scary 2nd start: 1325209 || Scary 2nd end: 1522208\n",
      "- Locs in sequence: Scary 1st: 6 || Scary 2nd: 10\n",
      "- Number of interlude videos (no bluVid): 1\n",
      "- Low Arousal Interlude videos: 1\n",
      "- Log Ratio: 0.0\n",
      "- Interlude duration (with bluVid): 386751.0\n",
      "Participant 15\n",
      "- Sequence ID: 15\n",
      "- Sequence: [10, 11, 3, 11, 5, 11, 1, 11, 7, 11, 2, 11, 4, 11, 8, 11, 6, 12]\n",
      "- Timepoints: Scary 1st start: 1030876 || Scary 1st end: 1227875 || Scary 2nd start: 1921084 || Scary 2nd end: 2064833\n",
      "- Locs in sequence: Scary 1st: 8 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 2\n",
      "- Low Arousal Interlude videos: 1\n",
      "- Log Ratio: -0.4055\n",
      "- Interlude duration (with bluVid): 693209.0\n",
      "Participant 16\n",
      "- Sequence ID: 16\n",
      "- Sequence: [10, 11, 2, 11, 6, 11, 4, 11, 8, 11, 3, 11, 1, 11, 7, 11, 5, 12]\n",
      "- Timepoints: Scary 1st start: 1061459 || Scary 1st end: 1205208 || Scary 2nd start: 1869459 || Scary 2nd end: 2066458\n",
      "- Locs in sequence: Scary 1st: 8 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 2\n",
      "- Low Arousal Interlude videos: 1\n",
      "- Log Ratio: -0.4055\n",
      "- Interlude duration (with bluVid): 664251.0\n",
      "Participant 17\n",
      "- Sequence ID: 17\n",
      "- Sequence: [10, 11, 7, 11, 5, 11, 3, 11, 1, 11, 8, 11, 6, 11, 4, 11, 2, 12]\n",
      "- Timepoints: Scary 1st start: 221501 || Scary 1st end: 418500 || Scary 2nd start: 1347876 || Scary 2nd end: 1491625\n",
      "- Locs in sequence: Scary 1st: 2 || Scary 2nd: 10\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: -0.2877\n",
      "- Interlude duration (with bluVid): 929376.0\n",
      "Participant 18\n",
      "- Sequence ID: 18\n",
      "- Sequence: [10, 11, 2, 11, 8, 11, 4, 11, 6, 11, 1, 11, 3, 11, 7, 11, 5, 12]\n",
      "- Timepoints: Scary 1st start: 514584 || Scary 1st end: 658333 || Scary 2nd start: 1869459 || Scary 2nd end: 2066458\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 4\n",
      "- Low Arousal Interlude videos: 3\n",
      "- Log Ratio: -0.2231\n",
      "- Interlude duration (with bluVid): 1211126.0\n",
      "Participant 19\n",
      "- Sequence ID: 19\n",
      "- Sequence: [10, 11, 3, 11, 1, 11, 7, 11, 5, 11, 4, 11, 2, 11, 6, 11, 8, 12]\n",
      "- Timepoints: Scary 1st start: 765751 || Scary 1st end: 962750 || Scary 2nd start: 2187834 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 6 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 4\n",
      "- Low Arousal Interlude videos: 3\n",
      "- Log Ratio: -0.2231\n",
      "- Interlude duration (with bluVid): 1225084.0\n",
      "Participant 20\n",
      "- Sequence ID: 20\n",
      "- Sequence: [10, 11, 4, 11, 8, 11, 2, 11, 6, 11, 3, 11, 1, 11, 5, 11, 7, 12]\n",
      "- Timepoints: Scary 1st start: 501626 || Scary 1st end: 645375 || Scary 2nd start: 2134584 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 5\n",
      "- Low Arousal Interlude videos: 3\n",
      "- Log Ratio: -0.4055\n",
      "- Interlude duration (with bluVid): 1489209.0\n",
      "Participant 21\n",
      "- Sequence ID: 21\n",
      "- Sequence: [10, 11, 1, 11, 5, 11, 3, 11, 7, 11, 6, 11, 4, 11, 2, 11, 8, 12]\n",
      "- Timepoints: Scary 1st start: 1030876 || Scary 1st end: 1227875 || Scary 2nd start: 2187834 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 8 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: -0.2877\n",
      "- Interlude duration (with bluVid): 959959.0\n",
      "Participant 22\n",
      "- Sequence ID: 22\n",
      "- Sequence: [10, 11, 2, 11, 8, 11, 4, 11, 6, 11, 7, 11, 5, 11, 3, 11, 1, 12]\n",
      "- Timepoints: Scary 1st start: 514584 || Scary 1st end: 658333 || Scary 2nd start: 1325209 || Scary 2nd end: 1522208\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 10\n",
      "- Number of interlude videos (no bluVid): 2\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: 0.0\n",
      "- Interlude duration (with bluVid): 666876.0\n",
      "Participant 23\n",
      "- Sequence ID: 23\n",
      "- Sequence: [10, 11, 7, 11, 1, 11, 3, 11, 5, 11, 8, 11, 6, 11, 4, 11, 2, 12]\n",
      "- Timepoints: Scary 1st start: 221501 || Scary 1st end: 418500 || Scary 2nd start: 1347876 || Scary 2nd end: 1491625\n",
      "- Locs in sequence: Scary 1st: 2 || Scary 2nd: 10\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 2\n",
      "- Log Ratio: -0.2877\n",
      "- Interlude duration (with bluVid): 929376.0\n",
      "Participant 24\n",
      "- Sequence ID: 24\n",
      "- Sequence: [10, 11, 6, 11, 8, 11, 4, 11, 2, 11, 5, 11, 3, 11, 1, 11, 7, 12]\n",
      "- Timepoints: Scary 1st start: 488251 || Scary 1st end: 632000 || Scary 2nd start: 2134584 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 5\n",
      "- Low Arousal Interlude videos: 3\n",
      "- Log Ratio: -0.4055\n",
      "- Interlude duration (with bluVid): 1502584.0\n",
      "Participant 25\n",
      "- Sequence ID: 25\n",
      "- Sequence: [10, 11, 1, 11, 7, 11, 5, 11, 3, 11, 2, 11, 6, 11, 8, 11, 4, 12]\n",
      "- Timepoints: Scary 1st start: 527084 || Scary 1st end: 724083 || Scary 2nd start: 1907709 || Scary 2nd end: 2051458\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 4\n",
      "- Low Arousal Interlude videos: 3\n",
      "- Log Ratio: -0.2231\n",
      "- Interlude duration (with bluVid): 1183626.0\n",
      "Participant 26\n",
      "- Sequence ID: 26\n",
      "- Sequence: [10, 11, 6, 11, 8, 11, 4, 11, 2, 11, 3, 11, 5, 11, 7, 11, 1, 12]\n",
      "- Timepoints: Scary 1st start: 488251 || Scary 1st end: 632000 || Scary 2nd start: 1829001 || Scary 2nd end: 2026000\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 4\n",
      "- Low Arousal Interlude videos: 3\n",
      "- Log Ratio: -0.2231\n",
      "- Interlude duration (with bluVid): 1197001.0\n",
      "Participant 27\n",
      "- Sequence ID: 27\n",
      "- Sequence: [10, 11, 3, 11, 5, 11, 7, 11, 1, 11, 4, 11, 2, 11, 8, 11, 6, 12]\n",
      "- Timepoints: Scary 1st start: 725293 || Scary 1st end: 922292 || Scary 2nd start: 1921084 || Scary 2nd end: 2064833\n",
      "- Locs in sequence: Scary 1st: 6 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 3\n",
      "- Low Arousal Interlude videos: 1\n",
      "- Log Ratio: -0.6931\n",
      "- Interlude duration (with bluVid): 998792.0\n",
      "Participant 28\n",
      "- Sequence ID: 28\n",
      "- Sequence: [10, 11, 8, 11, 6, 11, 2, 11, 4, 11, 5, 11, 3, 11, 7, 11, 1, 12]\n",
      "- Timepoints: Scary 1st start: 221501 || Scary 1st end: 365250 || Scary 2nd start: 1829001 || Scary 2nd end: 2026000\n",
      "- Locs in sequence: Scary 1st: 2 || Scary 2nd: 14\n",
      "- Number of interlude videos (no bluVid): 5\n",
      "- Low Arousal Interlude videos: 4\n",
      "- Log Ratio: -0.1823\n",
      "- Interlude duration (with bluVid): 1463751.0\n",
      "Participant 29\n",
      "- Sequence ID: 29\n",
      "- Sequence: [10, 11, 1, 11, 3, 11, 7, 11, 5, 11, 4, 11, 6, 11, 2, 11, 8, 12]\n",
      "- Timepoints: Scary 1st start: 765751 || Scary 1st end: 962750 || Scary 2nd start: 2187834 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 6 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 4\n",
      "- Low Arousal Interlude videos: 3\n",
      "- Log Ratio: -0.2231\n",
      "- Interlude duration (with bluVid): 1225084.0\n",
      "Participant 30\n",
      "- Sequence ID: 30\n",
      "- Sequence: [10, 11, 6, 11, 8, 11, 2, 11, 4, 11, 5, 11, 3, 11, 1, 11, 7, 12]\n",
      "- Timepoints: Scary 1st start: 488251 || Scary 1st end: 632000 || Scary 2nd start: 2134584 || Scary 2nd end: 2331583\n",
      "- Locs in sequence: Scary 1st: 4 || Scary 2nd: 16\n",
      "- Number of interlude videos (no bluVid): 5\n",
      "- Low Arousal Interlude videos: 3\n",
      "- Log Ratio: -0.4055\n",
      "- Interlude duration (with bluVid): 1502584.0\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the metadata\n",
    "videos_data, participant_data, duration_data, sequence_order_data = retrieve_metadata(metadata_dir)\n",
    "\n",
    "# Call the Independent Variable process that extracts the IVs from each participant\n",
    "compute_independent_variables(sequence_order_data, participant_data, videos_data, total_num_participants)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a6381c-5e2b-4913-9beb-c38f0a97f0c6",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21eac49-68cd-498e-ab9a-198fd08a1e5a",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed5c51c4-0116-4de1-b275-00d133b19ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>InterludeDuration</th>\n",
       "      <th>Interlude Video Count</th>\n",
       "      <th>Interlude Low Arousal</th>\n",
       "      <th>LowArousalRatioLog</th>\n",
       "      <th>scary_1st_ecg_Heart Rate</th>\n",
       "      <th>scary_1st_ecg_HRV SDNN</th>\n",
       "      <th>scary_1st_ecg_Mean RR Interval</th>\n",
       "      <th>scary_2nd_ecg_Heart Rate</th>\n",
       "      <th>scary_2nd_ecg_HRV SDNN</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_ecg_Mean RR Interval</th>\n",
       "      <th>scary_1st_gsr_SCL</th>\n",
       "      <th>scary_1st_gsr_SCR</th>\n",
       "      <th>scary_1st_gsr_Peak Amplitude</th>\n",
       "      <th>scary_2nd_gsr_SCL</th>\n",
       "      <th>scary_2nd_gsr_SCR</th>\n",
       "      <th>scary_2nd_gsr_Peak Amplitude</th>\n",
       "      <th>diff_gsr_SCL</th>\n",
       "      <th>diff_gsr_SCR</th>\n",
       "      <th>diff_gsr_Peak Amplitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>959959.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.2877</td>\n",
       "      <td>84.237003</td>\n",
       "      <td>108.081025</td>\n",
       "      <td>712.752727</td>\n",
       "      <td>78.997529</td>\n",
       "      <td>44.442609</td>\n",
       "      <td>...</td>\n",
       "      <td>46.906847</td>\n",
       "      <td>10.872198</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.510694</td>\n",
       "      <td>5.964512</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.066512</td>\n",
       "      <td>-4.907686</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-0.444182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>929376.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.2877</td>\n",
       "      <td>66.030824</td>\n",
       "      <td>51.130114</td>\n",
       "      <td>909.159236</td>\n",
       "      <td>65.516855</td>\n",
       "      <td>71.416938</td>\n",
       "      <td>...</td>\n",
       "      <td>7.116465</td>\n",
       "      <td>26.915070</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>1.684899</td>\n",
       "      <td>30.270737</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>1.113085</td>\n",
       "      <td>3.355667</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>-0.571813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1237459.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.5108</td>\n",
       "      <td>73.680695</td>\n",
       "      <td>89.976035</td>\n",
       "      <td>811.371901</td>\n",
       "      <td>83.366732</td>\n",
       "      <td>95.097323</td>\n",
       "      <td>...</td>\n",
       "      <td>-91.967860</td>\n",
       "      <td>27.252515</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.658351</td>\n",
       "      <td>29.508119</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>0.773130</td>\n",
       "      <td>2.255604</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.114779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>890543.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>55.450141</td>\n",
       "      <td>112.026191</td>\n",
       "      <td>1074.719697</td>\n",
       "      <td>56.315242</td>\n",
       "      <td>86.916162</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.577620</td>\n",
       "      <td>18.304764</td>\n",
       "      <td>-0.005237</td>\n",
       "      <td>1.903517</td>\n",
       "      <td>27.535077</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>2.666756</td>\n",
       "      <td>9.230312</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.763239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>623793.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>68.818342</td>\n",
       "      <td>95.952448</td>\n",
       "      <td>872.084444</td>\n",
       "      <td>73.653347</td>\n",
       "      <td>76.812719</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.398730</td>\n",
       "      <td>36.639102</td>\n",
       "      <td>-0.000272</td>\n",
       "      <td>4.711764</td>\n",
       "      <td>37.999770</td>\n",
       "      <td>-0.004878</td>\n",
       "      <td>3.013565</td>\n",
       "      <td>1.360668</td>\n",
       "      <td>-0.004606</td>\n",
       "      <td>-1.698198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  InterludeDuration  Interlude Video Count  \\\n",
       "0            1           959959.0                    3.0   \n",
       "1            2           929376.0                    3.0   \n",
       "2            3          1237459.0                    4.0   \n",
       "3            4           890543.0                    3.0   \n",
       "4            5           623793.0                    2.0   \n",
       "\n",
       "   Interlude Low Arousal  LowArousalRatioLog  scary_1st_ecg_Heart Rate  \\\n",
       "0                    2.0             -0.2877                 84.237003   \n",
       "1                    2.0             -0.2877                 66.030824   \n",
       "2                    2.0             -0.5108                 73.680695   \n",
       "3                    3.0              0.0000                 55.450141   \n",
       "4                    2.0              0.0000                 68.818342   \n",
       "\n",
       "   scary_1st_ecg_HRV SDNN  scary_1st_ecg_Mean RR Interval  \\\n",
       "0              108.081025                      712.752727   \n",
       "1               51.130114                      909.159236   \n",
       "2               89.976035                      811.371901   \n",
       "3              112.026191                     1074.719697   \n",
       "4               95.952448                      872.084444   \n",
       "\n",
       "   scary_2nd_ecg_Heart Rate  scary_2nd_ecg_HRV SDNN  ...  \\\n",
       "0                 78.997529               44.442609  ...   \n",
       "1                 65.516855               71.416938  ...   \n",
       "2                 83.366732               95.097323  ...   \n",
       "3                 56.315242               86.916162  ...   \n",
       "4                 73.653347               76.812719  ...   \n",
       "\n",
       "   diff_ecg_Mean RR Interval  scary_1st_gsr_SCL  scary_1st_gsr_SCR  \\\n",
       "0                  46.906847          10.872198          -0.000051   \n",
       "1                   7.116465          26.915070          -0.000209   \n",
       "2                 -91.967860          27.252515           0.001772   \n",
       "3                  -8.577620          18.304764          -0.005237   \n",
       "4                 -57.398730          36.639102          -0.000272   \n",
       "\n",
       "   scary_1st_gsr_Peak Amplitude  scary_2nd_gsr_SCL  scary_2nd_gsr_SCR  \\\n",
       "0                      0.510694           5.964512           0.000098   \n",
       "1                      1.684899          30.270737           0.001399   \n",
       "2                      0.658351          29.508119          -0.002480   \n",
       "3                      1.903517          27.535077          -0.002198   \n",
       "4                      4.711764          37.999770          -0.004878   \n",
       "\n",
       "   scary_2nd_gsr_Peak Amplitude  diff_gsr_SCL  diff_gsr_SCR  \\\n",
       "0                      0.066512     -4.907686      0.000149   \n",
       "1                      1.113085      3.355667      0.001609   \n",
       "2                      0.773130      2.255604     -0.004251   \n",
       "3                      2.666756      9.230312      0.003039   \n",
       "4                      3.013565      1.360668     -0.004606   \n",
       "\n",
       "   diff_gsr_Peak Amplitude  \n",
       "0                -0.444182  \n",
       "1                -0.571813  \n",
       "2                 0.114779  \n",
       "3                 0.763239  \n",
       "4                -1.698198  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the IV and the DV CSV files \n",
    "iv_df = pd.read_csv('preprocessed_data/iv_data.csv')\n",
    "if CPA:\n",
    "    dv_df = pd.read_csv('preprocessed_data/dv_data_cpa.csv')\n",
    "else:\n",
    "    dv_df = pd.read_csv('preprocessed_data/dv_data.csv')\n",
    "\n",
    "combined_df = pd.concat([dv_df.iloc[:, :1], iv_df.iloc[:, 1:], dv_df.iloc[:, 1:]], axis=1) # Keep the column \"Participant\" of the dv dataframe and add the iv columns after it.\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d556e40-1ac6-4395-96e2-07eaeb2890e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iv_dv_clean CSV saved to preprocessed_data/iv_dv_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Transform Interlude Duration to seconds\n",
    "combined_df[\"InterludeDuration\"] = combined_df[\"InterludeDuration\"] / 1000\n",
    "\n",
    "# Round all values to 4 decimals\n",
    "combined_df = combined_df.round(4)\n",
    "combined_df.head()\n",
    "\n",
    "# Save the combined DataFrame\n",
    "output_path = 'preprocessed_data/iv_dv_data.csv'  \n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f'iv_dv_clean CSV saved to {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5cf78d-923b-448d-b7f9-3f3af93c3904",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec4b1c6a-d8b3-4f3c-8892-03660f5373b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>InterludeDuration</th>\n",
       "      <th>Interlude Video Count</th>\n",
       "      <th>Interlude Low Arousal</th>\n",
       "      <th>LowArousalRatioLog</th>\n",
       "      <th>scary_1st_ecg_Heart Rate</th>\n",
       "      <th>scary_1st_ecg_HRV SDNN</th>\n",
       "      <th>scary_1st_ecg_Mean RR Interval</th>\n",
       "      <th>scary_2nd_ecg_Heart Rate</th>\n",
       "      <th>scary_2nd_ecg_HRV SDNN</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_ecg_Mean RR Interval</th>\n",
       "      <th>scary_1st_gsr_SCL</th>\n",
       "      <th>scary_1st_gsr_SCR</th>\n",
       "      <th>scary_1st_gsr_Peak Amplitude</th>\n",
       "      <th>scary_2nd_gsr_SCL</th>\n",
       "      <th>scary_2nd_gsr_SCR</th>\n",
       "      <th>scary_2nd_gsr_Peak Amplitude</th>\n",
       "      <th>diff_gsr_SCL</th>\n",
       "      <th>diff_gsr_SCR</th>\n",
       "      <th>diff_gsr_Peak Amplitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>959.959</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.2877</td>\n",
       "      <td>84.2370</td>\n",
       "      <td>108.0810</td>\n",
       "      <td>712.7527</td>\n",
       "      <td>78.9975</td>\n",
       "      <td>44.4426</td>\n",
       "      <td>...</td>\n",
       "      <td>46.9068</td>\n",
       "      <td>10.8722</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>5.9645</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>-4.9077</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.4442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>929.376</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.2877</td>\n",
       "      <td>66.0308</td>\n",
       "      <td>51.1301</td>\n",
       "      <td>909.1592</td>\n",
       "      <td>65.5169</td>\n",
       "      <td>71.4169</td>\n",
       "      <td>...</td>\n",
       "      <td>7.1165</td>\n",
       "      <td>26.9151</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>1.6849</td>\n",
       "      <td>30.2707</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>1.1131</td>\n",
       "      <td>3.3557</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.5718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1237.459</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.5108</td>\n",
       "      <td>73.6807</td>\n",
       "      <td>89.9760</td>\n",
       "      <td>811.3719</td>\n",
       "      <td>83.3667</td>\n",
       "      <td>95.0973</td>\n",
       "      <td>...</td>\n",
       "      <td>-91.9679</td>\n",
       "      <td>27.2525</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>29.5081</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.7731</td>\n",
       "      <td>2.2556</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>890.543</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>55.4501</td>\n",
       "      <td>112.0262</td>\n",
       "      <td>1074.7197</td>\n",
       "      <td>56.3152</td>\n",
       "      <td>86.9162</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.5776</td>\n",
       "      <td>18.3048</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>1.9035</td>\n",
       "      <td>27.5351</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>2.6668</td>\n",
       "      <td>9.2303</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.7632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>623.793</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>68.8183</td>\n",
       "      <td>95.9524</td>\n",
       "      <td>872.0844</td>\n",
       "      <td>73.6533</td>\n",
       "      <td>76.8127</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.3987</td>\n",
       "      <td>36.6391</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>4.7118</td>\n",
       "      <td>37.9998</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>3.0136</td>\n",
       "      <td>1.3607</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-1.6982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  InterludeDuration  Interlude Video Count  \\\n",
       "0            1            959.959                    3.0   \n",
       "1            2            929.376                    3.0   \n",
       "2            3           1237.459                    4.0   \n",
       "3            4            890.543                    3.0   \n",
       "4            5            623.793                    2.0   \n",
       "\n",
       "   Interlude Low Arousal  LowArousalRatioLog  scary_1st_ecg_Heart Rate  \\\n",
       "0                    2.0             -0.2877                   84.2370   \n",
       "1                    2.0             -0.2877                   66.0308   \n",
       "2                    2.0             -0.5108                   73.6807   \n",
       "3                    3.0              0.0000                   55.4501   \n",
       "4                    2.0              0.0000                   68.8183   \n",
       "\n",
       "   scary_1st_ecg_HRV SDNN  scary_1st_ecg_Mean RR Interval  \\\n",
       "0                108.0810                        712.7527   \n",
       "1                 51.1301                        909.1592   \n",
       "2                 89.9760                        811.3719   \n",
       "3                112.0262                       1074.7197   \n",
       "4                 95.9524                        872.0844   \n",
       "\n",
       "   scary_2nd_ecg_Heart Rate  scary_2nd_ecg_HRV SDNN  ...  \\\n",
       "0                   78.9975                 44.4426  ...   \n",
       "1                   65.5169                 71.4169  ...   \n",
       "2                   83.3667                 95.0973  ...   \n",
       "3                   56.3152                 86.9162  ...   \n",
       "4                   73.6533                 76.8127  ...   \n",
       "\n",
       "   diff_ecg_Mean RR Interval  scary_1st_gsr_SCL  scary_1st_gsr_SCR  \\\n",
       "0                    46.9068            10.8722            -0.0001   \n",
       "1                     7.1165            26.9151            -0.0002   \n",
       "2                   -91.9679            27.2525             0.0018   \n",
       "3                    -8.5776            18.3048            -0.0052   \n",
       "4                   -57.3987            36.6391            -0.0003   \n",
       "\n",
       "   scary_1st_gsr_Peak Amplitude  scary_2nd_gsr_SCL  scary_2nd_gsr_SCR  \\\n",
       "0                        0.5107             5.9645             0.0001   \n",
       "1                        1.6849            30.2707             0.0014   \n",
       "2                        0.6584            29.5081            -0.0025   \n",
       "3                        1.9035            27.5351            -0.0022   \n",
       "4                        4.7118            37.9998            -0.0049   \n",
       "\n",
       "   scary_2nd_gsr_Peak Amplitude  diff_gsr_SCL  diff_gsr_SCR  \\\n",
       "0                        0.0665       -4.9077        0.0001   \n",
       "1                        1.1131        3.3557        0.0016   \n",
       "2                        0.7731        2.2556       -0.0043   \n",
       "3                        2.6668        9.2303        0.0030   \n",
       "4                        3.0136        1.3607       -0.0046   \n",
       "\n",
       "   diff_gsr_Peak Amplitude  \n",
       "0                  -0.4442  \n",
       "1                  -0.5718  \n",
       "2                   0.1148  \n",
       "3                   0.7632  \n",
       "4                  -1.6982  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data_path = \"preprocessed_data/iv_dv_data.csv\"\n",
    "data = load_csv_data(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fda6e8ee-926d-4cec-8288-2f62bfcd6f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InterludeDuration</th>\n",
       "      <th>LowArousalRatioLog</th>\n",
       "      <th>diff_ecg_Mean RR Interval</th>\n",
       "      <th>diff_ecg_Heart Rate</th>\n",
       "      <th>diff_gsr_Peak Amplitude</th>\n",
       "      <th>diff_gsr_SCL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>959.959</td>\n",
       "      <td>-0.2877</td>\n",
       "      <td>46.9068</td>\n",
       "      <td>-5.2395</td>\n",
       "      <td>-0.4442</td>\n",
       "      <td>-4.9077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929.376</td>\n",
       "      <td>-0.2877</td>\n",
       "      <td>7.1165</td>\n",
       "      <td>-0.5140</td>\n",
       "      <td>-0.5718</td>\n",
       "      <td>3.3557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237.459</td>\n",
       "      <td>-0.5108</td>\n",
       "      <td>-91.9679</td>\n",
       "      <td>9.6860</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>2.2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>890.543</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-8.5776</td>\n",
       "      <td>0.8651</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>9.2303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>623.793</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-57.3987</td>\n",
       "      <td>4.8350</td>\n",
       "      <td>-1.6982</td>\n",
       "      <td>1.3607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InterludeDuration  LowArousalRatioLog  diff_ecg_Mean RR Interval  \\\n",
       "0            959.959             -0.2877                    46.9068   \n",
       "1            929.376             -0.2877                     7.1165   \n",
       "2           1237.459             -0.5108                   -91.9679   \n",
       "3            890.543              0.0000                    -8.5776   \n",
       "4            623.793              0.0000                   -57.3987   \n",
       "\n",
       "   diff_ecg_Heart Rate  diff_gsr_Peak Amplitude  diff_gsr_SCL  \n",
       "0              -5.2395                  -0.4442       -4.9077  \n",
       "1              -0.5140                  -0.5718        3.3557  \n",
       "2               9.6860                   0.1148        2.2556  \n",
       "3               0.8651                   0.7632        9.2303  \n",
       "4               4.8350                  -1.6982        1.3607  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only relevant columns (differences)\n",
    "#relevant_columns = ['InterludeDuration', 'LowArousalRatioLog', 'diff_ecg_Mean RR Interval', 'diff_ecg_Heart Rate', 'diff_ecg_HRV SDNN', 'diff_gsr_Peak Amplitude', 'diff_gsr_SCR', 'diff_gsr_SCL']\n",
    "relevant_columns = ['InterludeDuration', 'LowArousalRatioLog', 'diff_ecg_Mean RR Interval', 'diff_ecg_Heart Rate', 'diff_gsr_Peak Amplitude', 'diff_gsr_SCL']\n",
    "data = data[relevant_columns]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24a12e3a-0933-4bdd-a93e-04b46f397da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InterludeDuration</th>\n",
       "      <th>LowArousalRatioLog</th>\n",
       "      <th>diff_ecg_Mean RR Interval</th>\n",
       "      <th>diff_ecg_Heart Rate</th>\n",
       "      <th>diff_gsr_Peak Amplitude</th>\n",
       "      <th>diff_gsr_SCL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>InterludeDuration</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.331677</td>\n",
       "      <td>0.096739</td>\n",
       "      <td>-0.065437</td>\n",
       "      <td>0.425790</td>\n",
       "      <td>-0.071298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowArousalRatioLog</th>\n",
       "      <td>-0.331677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055395</td>\n",
       "      <td>-0.043734</td>\n",
       "      <td>-0.185946</td>\n",
       "      <td>0.113081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_ecg_Mean RR Interval</th>\n",
       "      <td>0.096739</td>\n",
       "      <td>-0.055395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.971238</td>\n",
       "      <td>-0.080333</td>\n",
       "      <td>-0.553329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_ecg_Heart Rate</th>\n",
       "      <td>-0.065437</td>\n",
       "      <td>-0.043734</td>\n",
       "      <td>-0.971238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097302</td>\n",
       "      <td>0.518646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_gsr_Peak Amplitude</th>\n",
       "      <td>0.425790</td>\n",
       "      <td>-0.185946</td>\n",
       "      <td>-0.080333</td>\n",
       "      <td>0.097302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.563505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_gsr_SCL</th>\n",
       "      <td>-0.071298</td>\n",
       "      <td>0.113081</td>\n",
       "      <td>-0.553329</td>\n",
       "      <td>0.518646</td>\n",
       "      <td>0.563505</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           InterludeDuration  LowArousalRatioLog  \\\n",
       "InterludeDuration                   1.000000           -0.331677   \n",
       "LowArousalRatioLog                 -0.331677            1.000000   \n",
       "diff_ecg_Mean RR Interval           0.096739           -0.055395   \n",
       "diff_ecg_Heart Rate                -0.065437           -0.043734   \n",
       "diff_gsr_Peak Amplitude             0.425790           -0.185946   \n",
       "diff_gsr_SCL                       -0.071298            0.113081   \n",
       "\n",
       "                           diff_ecg_Mean RR Interval  diff_ecg_Heart Rate  \\\n",
       "InterludeDuration                           0.096739            -0.065437   \n",
       "LowArousalRatioLog                         -0.055395            -0.043734   \n",
       "diff_ecg_Mean RR Interval                   1.000000            -0.971238   \n",
       "diff_ecg_Heart Rate                        -0.971238             1.000000   \n",
       "diff_gsr_Peak Amplitude                    -0.080333             0.097302   \n",
       "diff_gsr_SCL                               -0.553329             0.518646   \n",
       "\n",
       "                           diff_gsr_Peak Amplitude  diff_gsr_SCL  \n",
       "InterludeDuration                         0.425790     -0.071298  \n",
       "LowArousalRatioLog                       -0.185946      0.113081  \n",
       "diff_ecg_Mean RR Interval                -0.080333     -0.553329  \n",
       "diff_ecg_Heart Rate                       0.097302      0.518646  \n",
       "diff_gsr_Peak Amplitude                   1.000000      0.563505  \n",
       "diff_gsr_SCL                              0.563505      1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Pearson correlation matrix\n",
    "correlation_matrix = data.corr(method='pearson')\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1209d0e-2bce-4025-b887-17154f3b0a71",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3554487620.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    stop running here\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop running here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa74f2-19a5-4a6d-b46c-7e3201ec0ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb3b56-1781-4928-8718-fabddb70dc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0c0ad-2814-49ba-aee2-3055f70fbcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92b530ab-ef55-4765-89c5-c8c274abb342",
   "metadata": {},
   "source": [
    "### Regression Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a061d-7bf9-4b25-86f2-5e4ee0c00ba5",
   "metadata": {},
   "source": [
    "### NOTE: ASK LUKAS \n",
    "### 1)problem if the interaction term is 0?\n",
    "### 2)when checking assumptions with or without interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913bffe-4e18-4aa5-bf2e-1e0a9f06cfa8",
   "metadata": {},
   "source": [
    "### Linear Multiple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e17ec-efcc-4834-b813-ae4c8d4dda4e",
   "metadata": {},
   "source": [
    "##### Assumptions Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbcf46d-9e7f-4526-935c-41fefe9f5f60",
   "metadata": {},
   "source": [
    "###### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf844d23-08c2-4b63-bb01-0178730ccca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors and response variables\n",
    "X = data[['InterludeDuration', 'LowArousalRatioLog']]\n",
    "y_vars = ['diff_ecg_Mean RR Interval', 'diff_ecg_Heart Rate', 'diff_gsr_Peak Amplitude', 'diff_gsr_SCL']\n",
    "\n",
    "# Define model with interaction term\n",
    "X_w_interaction = X.copy()\n",
    "X_w_interaction['Interaction'] = X_w_interaction['InterludeDuration'] * X_w_interaction['LowArousalRatioLog']\n",
    "\n",
    "# Add constant to the predictors\n",
    "X = sm.add_constant(X)\n",
    "X_w_interaction = sm.add_constant(X_w_interaction)\n",
    "\n",
    "# Fit models and store in dictionary\n",
    "models = {}\n",
    "\n",
    "for i, response_var in enumerate(y_vars, 1):\n",
    "    model_name = f'model{i}'\n",
    "    models[model_name] = {\n",
    "        'model_no_interaction': sm.OLS(data[response_var], X).fit(),\n",
    "        'model_w_interaction': sm.OLS(data[response_var], X_w_interaction).fit(),\n",
    "        'response_var': response_var\n",
    "    }\n",
    "\n",
    "\n",
    "def derive_formula(model):\n",
    "    \"\"\" Derive linear formula from model \"\"\"\n",
    "    predictors = model.model.exog_names\n",
    "    response = model.model.endog_names\n",
    "    formula = f\"{response} ~ \" + \" + \".join(predictors)\n",
    "    return formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1b218-2436-4c08-8afe-618095ca13fc",
   "metadata": {},
   "source": [
    "###### Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacfe4c-918f-4cdf-a20f-f3e34b6d4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model1\" # put model here... ('model1', 'model2', 'model3', 'model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9411d93-62fa-4ce1-96a5-c57ada2e0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = models[model_name]\n",
    "model = model_info['model_no_interaction']\n",
    "# print(model.summary())\n",
    "response_var = model_info['response_var']\n",
    "print(f\"Selected model: {model_name}\\n-Predictors: {', '.join(X.columns.tolist())}\\n-Response Variable: {response_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b03471-6274-45fe-92e0-41d6e0a13881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linearity: Plot observed vs. predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(model.fittedvalues, data[response_var], alpha=0.6)\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Observed values')\n",
    "plt.title(f'Observed vs. Fitted values for {response_var}')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ad034-e01f-4bc0-9b4c-b4bd02f1ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Independence: Durbin-Watson test\n",
    "dw_test = sm.stats.durbin_watson(model.resid)\n",
    "print(f'Durbin-Watson statistic: {dw_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50009800-d337-4459-b27a-f224a2b1daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Homoscedasticity: Plot residuals vs. fitted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(model.fittedvalues, model.resid)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs. Fitted values')\n",
    "plt.show()\n",
    "\n",
    "# Breusch-Pagan test for homoscedasticity\n",
    "bp_test = het_breuschpagan(model.resid, model.model.exog)\n",
    "labels = ['LM Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value']\n",
    "print(dict(zip(labels, bp_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8de375-8f66-4284-801e-c17d116c17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Normality: Histogram and Q-Q plot of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(model.resid, kde=True)\n",
    "plt.xlabel('Residuals')\n",
    "plt.title('Histogram of residuals')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot\n",
    "sm.qqplot(model.resid, line='45')\n",
    "plt.title('Q-Q plot')\n",
    "plt.show()\n",
    "\n",
    "# Shapiro-Wilk test\n",
    "shapiro_test = shapiro(model.resid)\n",
    "print(f'Shapiro-Wilk test: {shapiro_test}')\n",
    "\n",
    "# Kolmogorov-Smirnov test\n",
    "ks_test = kstest(model.resid, 'norm')\n",
    "print(f'Kolmogorov-Smirnov test: {ks_test}')\n",
    "\n",
    "# Jarque-Bera test\n",
    "jb_test = jarque_bera(model.resid)\n",
    "print(f'Jarque-Bera test: {jb_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8baff9e-8bae-46a7-8e8f-dacafcdce9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Multicollinearity: Variance Inflation Factor (VIF)\n",
    "vif = pd.DataFrame()\n",
    "vif['Variable'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719bedc6-4985-4b6a-831b-92bc8e1ba6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Assumptions:\n",
    "\n",
    "# Influential Points: Cook's Distance\n",
    "influence = OLSInfluence(model)\n",
    "cooks_d = influence.cooks_distance[0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.stem(np.arange(len(cooks_d)), cooks_d, markerfmt=\",\")\n",
    "plt.title('Cooks Distance')\n",
    "plt.xlabel('Observation Index')\n",
    "plt.ylabel('Cooks Distance')\n",
    "plt.show()\n",
    "\n",
    "# Leverage plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(influence.hat_matrix_diag, model.resid)\n",
    "plt.xlabel('Leverage')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Leverage vs. Residuals')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.axvline(2 * (X.shape[1] + 1) / len(X), color='blue', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd483d-63cb-4ff1-ba14-dbc7defb7ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Linearity of Relationships: Partial Regression Plots\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sm.graphics.plot_partregress_grid(model, fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6e020-b002-421c-bf1d-c05326c41f22",
   "metadata": {},
   "source": [
    "##### Fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85e13f-48e6-4fa3-95c4-6cb1f72e01ae",
   "metadata": {},
   "source": [
    "###### change model here (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77872985-171c-43d6-bf35-be31b1fb4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"model\" # put model here... ('model1', 'model2', 'model3', 'model4')\n",
    "# ------\n",
    "model_info = models[model_name]\n",
    "model = model_info['model_no_interaction']\n",
    "# print(model.summary())\n",
    "response_var = model_info['response_var']\n",
    "print(f\"Selected model: {model_name}\\n-Predictors: {', '.join(X.columns.tolist())}\\n-Response Variable: {response_var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bde13a-d298-42e1-ad04-fc467d2e89d1",
   "metadata": {},
   "source": [
    "###### View model summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4d5a5-d4d1-4a86-9c2e-2c6eaa9ee994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print selected model results with and without the interaction term\n",
    "formula_no_interaction = derive_formula(models[model_name]['model_no_interaction'])\n",
    "formula_w_interaction = derive_formula(models[model_name]['model_w_interaction'])\n",
    "\n",
    "print(f\"Summary for {formula_no_interaction}:\")\n",
    "model = models[model_name]['model_no_interaction']\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d88a27-d289-44ce-8bc6-44a4b6e7d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Beta Coefficients\n",
    "beta_coefficients = model.params\n",
    "print(\"Beta Coefficients:\\n\", beta_coefficients)\n",
    "\n",
    "# Extract Confidence Intervals\n",
    "confidence_intervals = model.conf_int()\n",
    "confidence_intervals.columns = ['Lower CI', 'Upper CI']\n",
    "print(\"Confidence Intervals:\\n\", confidence_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de028f98-0150-428e-9c7c-86a4bf6228f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSummary for {formula_w_interaction}:\")\n",
    "model = models[model_name]['model_w_interaction']\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba25db-8e33-4807-a44b-ba6cc1db84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Beta Coefficients\n",
    "beta_coefficients = model.params\n",
    "print(\"Beta Coefficients:\\n\", beta_coefficients)\n",
    "\n",
    "# Extract Confidence Intervals\n",
    "confidence_intervals = model.conf_int()\n",
    "confidence_intervals.columns = ['Lower CI', 'Upper CI']\n",
    "print(\"Confidence Intervals:\\n\", confidence_intervals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c077999-c7ee-43cf-b338-58eb30e94ad8",
   "metadata": {},
   "source": [
    "# TODO: do not forget Rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556f28c-1d90-40a4-b3fc-9ab68bfdb804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a831a-f37c-429c-844a-9028a54aceba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2997335-d64e-4b62-aba6-e535df800228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7c456-736c-40dd-9b0f-b7371c14ecd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ded42a-787a-4512-b3f3-907411873833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5465df2-5558-4ee8-a8ce-10c541b13f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df84bca-295b-455a-9421-17e35301a86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03052be7-3477-4ed9-9520-514698a0690c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03608f89-9dee-418a-b8ca-7f567be40fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c195a6ab-ff88-4d14-b2ca-c65e5e64c1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a730f8-6864-434e-86d8-e85878d94a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02d112-7bf4-4b45-a01e-711ca5464f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74b31767-5b03-47dc-a74c-ba2c6b19fc51",
   "metadata": {},
   "source": [
    "### Multivariate Multiple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b81457-3008-4129-9518-d56ee2efad65",
   "metadata": {},
   "source": [
    "#### Assumptions Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c19ba-66ca-464f-9cae-d02e9696bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1, y_2 = 'diff_ecg_Mean RR Interval', 'diff_gsr_Peak Amplitude'\n",
    "y_1, y_2 = 'diff_gsr_SCL', 'diff_gsr_Peak Amplitude'\n",
    "# y_1, y_2 = 'diff_ecg_Mean RR Interval', 'diff_gsr_SCL'\n",
    "# y_1, y_2 = 'diff_ecg_Mean RR Interval', 'diff_ecg_Heart Rate'\n",
    "#y_1, y_2 = 'diff_gsr_Peak Amplitude', 'diff_ecg_Heart Rate'\n",
    "dependent_vars = [y_1, y_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547ec90-5f02-4201-a514-729d046c9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the relevant columns\n",
    "relevant_columns = ['InterludeDuration', 'LowArousalRatioLog', y_1, y_2]\n",
    "mvar_data = data[relevant_columns]\n",
    "\n",
    "# Define the formula \n",
    "formula = f'Q(\"{y_1}\") + Q(\"{y_2}\") ~ Q(\"InterludeDuration\") + Q(\"LowArousalRatioLog\")'\n",
    "\n",
    "# Fit the multivariate model\n",
    "mvar_model = MANOVA.from_formula(formula, data=mvar_data)\n",
    "mvar_model_results = mvar_model.mv_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f23f7-aa7d-41e0-a708-fb99294cf29b",
   "metadata": {},
   "source": [
    "##### Assumptions checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364fdbfb-54ad-44e5-9a92-d2c9d59e7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linearity: Scatter plot matrix\n",
    "sns.pairplot(mvar_data)\n",
    "plt.title('Scatter plot matrix for checking linearity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43225abe-f0d4-4a12-b76b-1564f7e951aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Multicollinearity: Variance Inflation Factor (VIF) \n",
    "X_no_interaction = mvar_data[['InterludeDuration', 'LowArousalRatioLog']]\n",
    "vif_no_interaction = pd.DataFrame()\n",
    "vif_no_interaction['Variable'] = X_no_interaction.columns\n",
    "vif_no_interaction['VIF'] = [variance_inflation_factor(X_no_interaction.values, i) for i in range(X_no_interaction.shape[1])]\n",
    "print(f'Variance Inflation Factor (without interaction):\\n{vif_no_interaction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c18f4a-d73b-4451-8e76-c6b58f819d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Multivariate Normality: Shapiro-Wilk test for each dependent variable\n",
    "\n",
    "for var in dependent_vars:\n",
    "    shapiro_test = shapiro(mvar_data[var])\n",
    "    print(f'Shapiro-Wilk test for {var}: {shapiro_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f696c-0bf3-4339-b871-c7c5dfa7d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Homoscedasticity: Plot residuals vs. fitted values and Breusch-Pagan test\n",
    "\n",
    "# Fit OLS models for each dependent variable to get residuals\n",
    "X = mvar_data[['InterludeDuration', 'LowArousalRatioLog']]\n",
    "X = sm.add_constant(X)  \n",
    "\n",
    "residuals = {}\n",
    "for var in dependent_vars:\n",
    "    model = sm.OLS(mvar_data[var], X).fit()\n",
    "    residuals[var] = model.resid\n",
    "\n",
    "    # Plot residuals vs. fitted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(model.fittedvalues, model.resid)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel('Fitted values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title(f'Residuals vs. Fitted values for {var}')\n",
    "    plt.show()\n",
    "\n",
    "    # Breusch-Pagan test for homoscedasticity\n",
    "    bp_test = het_breuschpagan(model.resid, model.model.exog)\n",
    "    labels = ['LM Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value']\n",
    "    print(f'Breusch-Pagan test for {var}: {dict(zip(labels, bp_test))}')\n",
    "\n",
    "# Additional check: Plot residuals for normality\n",
    "for var, resid in residuals.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(resid, kde=True)\n",
    "    plt.xlabel('Residuals')\n",
    "    plt.title(f'Histogram of residuals for {var}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227bd811-c9d4-4cfc-9212-8a377ba4a0e4",
   "metadata": {},
   "source": [
    "#### Fit Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f908fe-5ec9-433f-8c5a-e269a6b463aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the relevant columns\n",
    "relevant_columns = ['InterludeDuration', 'LowArousalRatioLog', y_1, y_2]\n",
    "mvar_data = data[relevant_columns]\n",
    "\n",
    "mvar_data_w_interaction = mvar_data.copy()\n",
    "\n",
    "# Add the interaction term to the data\n",
    "mvar_data_w_interaction['Interaction'] = mvar_data['InterludeDuration'] * mvar_data['LowArousalRatioLog']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78062ef6-d5e2-4f7c-bac7-10a7a4bdd72b",
   "metadata": {},
   "source": [
    "###### Without interaction term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79c094-aa6a-40c4-953f-654d6ff34db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the formula without the interaction term\n",
    "formula_no_interaction = f'Q(\"{y_1}\") + Q(\"{y_2}\") ~ Q(\"InterludeDuration\") + Q(\"LowArousalRatioLog\")'\n",
    "\n",
    "# Fit the Multivariate Multiple Regression (MMR) model without the interaction term\n",
    "mvar_model_no_interaction = MANOVA.from_formula(formula_no_interaction, data=mvar_data)\n",
    "mvar_results_no_interaction = mvar_model_no_interaction.mv_test()\n",
    "\n",
    "# Display the results\n",
    "print(mvar_results_no_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ac644-3a39-4d3a-ba9e-7e78883dab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "mvar_data_no_interaction = mvar_data\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "coefficients = {}\n",
    "conf_intervals = {}\n",
    "\n",
    "# Fit separate OLS models for each dependent variable\n",
    "for y_var in dependent_vars:\n",
    "    formula = f'Q(\"{y_var}\") ~ Q(\"InterludeDuration\") + Q(\"LowArousalRatioLog\")'\n",
    "    model = ols(formula, data=mvar_data_no_interaction).fit()\n",
    "    \n",
    "    # Extract coefficients\n",
    "    coefficients[y_var] = model.params\n",
    "    \n",
    "    # Extract confidence intervals\n",
    "    conf_intervals[y_var] = model.conf_int()\n",
    "    conf_intervals[y_var].columns = ['Lower CI', 'Upper CI']\n",
    "\n",
    "# Convert dictionaries to DataFrames for easier visualization\n",
    "coefficients_df = pd.DataFrame(coefficients)\n",
    "conf_intervals_df = pd.concat(conf_intervals, axis=1)\n",
    "\n",
    "print(\"Coefficients:\\n\", coefficients_df)\n",
    "print(\"\\nConfidence Intervals:\\n\", conf_intervals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b02518-4d42-4d88-916f-c0922e66bb13",
   "metadata": {},
   "source": [
    "###### With interaction term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471a62d-d6ca-4d07-bfbc-6f0cbd18bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the formula with interaction\n",
    "formula_w_interaction = f'Q(\"{y_1}\") + Q(\"{y_2}\") ~ Q(\"InterludeDuration\") + Q(\"LowArousalRatioLog\") + Interaction'\n",
    "\n",
    "# Fit the Mutlivariate Multiple Regression (MMR) model\n",
    "mvar_model_w_interaction = MANOVA.from_formula(formula_w_interaction, data=mvar_data_w_interaction)\n",
    "mvar_results_w_interaction = mvar_model_w_interaction.mv_test()\n",
    "\n",
    "# Display the results\n",
    "print(mvar_results_w_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80babe6d-e423-4898-bcbf-cd88ba1e1e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "coefficients = {}\n",
    "conf_intervals = {}\n",
    "\n",
    "# Fit separate OLS models for each dependent variable\n",
    "for y_var in dependent_vars:\n",
    "    formula = f'Q(\"{y_var}\") ~ Q(\"InterludeDuration\") + Q(\"LowArousalRatioLog\") + Interaction'\n",
    "    model = ols(formula, data=mvar_data_w_interaction).fit()\n",
    "    \n",
    "    # Extract coefficients\n",
    "    coefficients[y_var] = model.params\n",
    "    \n",
    "    # Extract confidence intervals\n",
    "    conf_intervals[y_var] = model.conf_int()\n",
    "    conf_intervals[y_var].columns = ['Lower CI', 'Upper CI']\n",
    "\n",
    "# Convert dictionaries to DataFrames for easier visualization\n",
    "coefficients_df = pd.DataFrame(coefficients)\n",
    "conf_intervals_df = pd.concat(conf_intervals, axis=1)\n",
    "\n",
    "print(\"Coefficients:\\n\", coefficients_df)\n",
    "print(\"\\nConfidence Intervals:\\n\", conf_intervals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2154027-cece-463e-8812-28ac21e8ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot diff_ecg_Heart Rate vs InterludeDuration\n",
    "sns.regplot(x='InterludeDuration', y=y_1, data=mvar_data, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(f'{y_1} vs InterludeDuration')\n",
    "\n",
    "sns.regplot(x='LowArousalRatioLog', y=y_1, data=mvar_data, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(f'{y_1} vs LowArousalRatioLog')\n",
    "\n",
    "sns.regplot(x='InterludeDuration', y=y_2, data=mvar_data, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(f'{y_2} vs InterludeDuration')\n",
    "\n",
    "sns.regplot(x='LowArousalRatioLog', y=y_2, data=mvar_data, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(f'{y_2} vs LowArousalRatioLog')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e381f-9fcb-462b-8810-330dd9c890f4",
   "metadata": {},
   "source": [
    "# TODO: do not forget Rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0914f4c-c16d-412f-b66f-188e13d06e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e44da24-8d60-440d-9516-4da18445c9ee",
   "metadata": {},
   "source": [
    "## G*Power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b6ba0-5cb1-464c-a102-48a2ff13caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (we can do it in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461264ba-eb26-47a7-93d5-0e3323a19800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf399d87-ee8b-4ee9-a6f5-5e9050dcb186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa83dd7-ed68-4922-a584-c1ce9222afcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28112b6f-dc6a-43e1-8136-820641e7499c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1adfb-dad2-4ef6-b0f5-3820e560f811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8248b-3413-4dc5-9854-6cbf4e49e280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d234a6-0fe4-4063-b34b-0181e914a279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e95eb-672c-4495-87ef-677a7965de8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ecd1b-9541-40d6-89bb-791675a01f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1a523-1376-43fe-bbed-2301609a5c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bea8e1-2f1f-498e-a109-cdb36a5965af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13cf00c-6eec-402d-ac9b-289d8bd3e850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6ac30-45a4-447f-8dc9-4a5f19d4a74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa0c0f-ade8-409c-9aca-8b1b9c0039d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271380fa-c061-4f97-b19a-6d92c5a64f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c2cd1-2d5d-4f0e-87e0-95048a226b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459130d-ce06-4c4c-9902-e6e7fcf06a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f7d15-13ef-40f5-8f8b-e90ee8ed9970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2138b61-b0e1-43fe-8007-26ef17284ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4e402f-60e2-41a1-ad84-9b43a0461ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbccd0b-f822-4590-98b3-861c16bd5116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28786f-6b14-456d-8262-3dfb13531662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a353bc-2665-4abf-a38a-de62bbb6a809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4048d28-c975-4b8b-a6d3-56d6ad732e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065b48a-fa99-44b5-9e96-82144ac491d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
